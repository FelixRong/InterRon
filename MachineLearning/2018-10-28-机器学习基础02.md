---
title: 机器学习02
date: 2018-10-28 15:25:03
tags:
categories: 机器学习
---
## 1、损失函数
<p style="text-indent: 2em;margin: 0px;padding: 0px">损失函数和代价函数是同一个东西，目标函数是一个与他们相关但更广的概念，对于目标函数来说在有约束条件下的最小化就是损失函数（loss function）。</p>
<p style="text-indent: 2em;margin: 0px;padding: 0px">我们给定 x，这三个函数都会输出一个 f(x),这个输出的 f(x)与真实值 y 可能是相同的，也可能是不同的，为了表示我们拟合的好坏，我们就用一个函数来度量拟合的程度，<!--more-->比如：L(Y,f(x))=(Y-f(x))^2，这个函数就称为损失函数(loss function)，或者叫代价函数(cost function)。损失函数越小，就代表模型拟合的越好。</p>

## 2、决策树（Decision Tree）
<p>基本的分类与回归方法</p>
<p style="text-indent: 2em;margin: 0px;padding: 0px">在分类问题中，表示基于特征对实例进行分类的过程，可以认为是if-then的集合，也可以认为是定义在特征空间与类空间上的条件概率分布。</p>
<p style="text-indent: 2em;margin: 0px;padding: 0px">决策树通常有三个步骤：特征选择、决策树的生成、决策树的修剪。</p>

## 3、随机森林（Random Forest）
随机森林特点：
	在当前所有算法中，具有极好的准确率
	能够有效地运行在大数据集上
	能够处理具有高维特征的输入样本，而且不需要降维
	能够评估各个特征在分类问题上的重要性
	在生成过程中，能够获取到内部生成误差的一种无偏估计
	对于缺省值问题也能够获得很好得结果
<p style="text-indent: 2em;margin: 0px;padding: 0px">随机森林就是通过集成学习的思想将多棵树集成的一种算法，它的基本单元是决策树，而它的本质属于机器学习的一大分支——集成学习（Ensemble Learning）方法。</p>
<p style="text-indent: 2em;margin: 0px;padding: 0px">其实从直观角度来解释，每棵决策树都是一个分类器（假设现在针对的是分类问题），那么对于一个输入样本，N棵树会有N个分类结果。而随机森林集成了所有的分类投票结果，将投票次数最多的类别指定为最终的输出，这就是一种最简单的 Bagging 思想。</p>

### 3.1、信息、熵以及信息增益的概念
<p style="text-indent: 2em;margin: 0px;padding: 0px">这三个基本概念是决策树的根本，是决策树利用特征来分类时，确定特征选取顺序的依据。</p>
引用香农的话来说，<span style="color: red">信息是用来消除随机不确定性的东西。</span>
某个类（Xi）的信息可定义为：
<span style="text-align:center;display:block;"><math xmlns='http://www.w3.org/1998/Math/MathML'> <mi> I </mi> <mfenced> <mrow> <mi> X </mi> <mo> = </mo> <msub> <mrow> <mi> x </mi> </mrow> <mrow> <mi> i </mi> </mrow> </msub> </mrow> </mfenced> <mo> = </mo> <mo> - </mo> <msub> <mrow> <mi> log </mi> </mrow> <mrow> <mn> 2 </mn> </mrow> </msub> <mi> p </mi> <mfenced> <mrow> <msub> <mrow> <mi> x </mi> </mrow> <mrow> <mi> i </mi> </mrow> </msub> </mrow> </mfenced> </math></span>
<p style="text-indent: 2em;margin: 0px;padding: 0px">I(x)用来表示随机变量的信息，p(xi)指是当xi发生时的概率。</p>
<p style="text-indent: 2em;margin: 0px;padding: 0px">一个消息可能性（概率）越小，其信息量越大。熵越大，代表该随机变量取特定值的时候具有的信息量越大。</p>
